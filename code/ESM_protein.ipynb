{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8812025,"sourceType":"datasetVersion","datasetId":5300559},{"sourceId":8916544,"sourceType":"datasetVersion","datasetId":5362312},{"sourceId":9098077,"sourceType":"datasetVersion","datasetId":5490741},{"sourceId":9115549,"sourceType":"datasetVersion","datasetId":5502087}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install fair-esm pandas scikit-learn torch lazypredict\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:57:52.762161Z","iopub.execute_input":"2024-09-26T16:57:52.762525Z","iopub.status.idle":"2024-09-26T16:58:06.837498Z","shell.execute_reply.started":"2024-09-26T16:57:52.762494Z","shell.execute_reply":"2024-09-26T16:58:06.836134Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nCollecting lazypredict\n  Downloading lazypredict-0.2.12-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from lazypredict) (8.1.7)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lazypredict) (4.66.4)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (from lazypredict) (4.2.0)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (from lazypredict) (2.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\nInstalling collected packages: fair-esm, lazypredict\nSuccessfully installed fair-esm-2.0.0 lazypredict-0.2.12\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# # Protein","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport esm\nimport numpy as np\nimport gc\nfrom torch.cuda.amp import autocast\n\n# Load the CSV file\nfile_path = '/kaggle/input/combineddb/combined_protein.csv'\ndata = pd.read_csv(file_path)\n\n# Load the pretrained ESM model\nmodel, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\nbatch_converter = alphabet.get_batch_converter()\n\n# Move model to GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Prepare the sequence data\nsequences = data['sequence'].tolist()\nlabels = data['label'].tolist()\n\nbatch_size = 10  # Reduce the batch size to fit within the available GPU memory\nall_embeddings = []\n\ndef mean_pooling(token_embeddings, attention_mask):\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask\n\nfor i in range(0, len(sequences), batch_size):\n    print(f\"Processing batch {i//batch_size + 1}/{len(sequences)//batch_size + 1}\")\n    batch_sequences = sequences[i:i+batch_size]\n    batch_labels = labels[i:i+batch_size]\n\n    data_tuples = [(f\"sequence_{j}\", seq) for j, seq in enumerate(batch_sequences)]\n    _, _, batch_tokens = batch_converter(data_tuples)\n    print(\"Batch tokens:\", batch_tokens.shape)\n\n    # Move batch tokens to GPU\n    batch_tokens = batch_tokens.to(device)\n\n    with torch.no_grad():\n        with autocast():\n            results = model(batch_tokens, repr_layers=[33])\n    token_embeddings = results[\"representations\"][33]\n\n    # Mean pooling to get fixed-size feature vectors\n    attention_mask = batch_tokens.ne(alphabet.padding_idx)\n    sequence_embeddings = mean_pooling(token_embeddings, attention_mask)\n\n    # Move sequence embeddings to CPU before converting to numpy\n    all_embeddings.append(sequence_embeddings.cpu().numpy())\n\n    # Clear the cache\n    torch.cuda.empty_cache()\n    gc.collect()  # Invoke garbage collector to free up memory\n\n# Concatenate all the embeddings\nall_embeddings = np.concatenate(all_embeddings, axis=0)\n\n# Convert the embeddings to a DataFrame\nembedding_df = pd.DataFrame(all_embeddings)\nembedding_df['label'] = labels\n\n# Save the DataFrame to a CSV file\nembedding_df.to_csv('/kaggle/working/embeddings_protien.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T16:58:06.841150Z","iopub.execute_input":"2024-09-26T16:58:06.841438Z","iopub.status.idle":"2024-09-26T17:32:00.843311Z","shell.execute_reply.started":"2024-09-26T16:58:06.841410Z","shell.execute_reply":"2024-09-26T17:32:00.842466Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt\" to /root/.cache/torch/hub/checkpoints/esm1b_t33_650M_UR50S.pt\nDownloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm1b_t33_650M_UR50S-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm1b_t33_650M_UR50S-contact-regression.pt\n","output_type":"stream"},{"name":"stdout","text":"Processing batch 1/906\nBatch tokens: torch.Size([10, 845])\nProcessing batch 2/906\nBatch tokens: torch.Size([10, 563])\nProcessing batch 3/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 4/906\nBatch tokens: torch.Size([10, 367])\nProcessing batch 5/906\nBatch tokens: torch.Size([10, 918])\nProcessing batch 6/906\nBatch tokens: torch.Size([10, 762])\nProcessing batch 7/906\nBatch tokens: torch.Size([10, 513])\nProcessing batch 8/906\nBatch tokens: torch.Size([10, 455])\nProcessing batch 9/906\nBatch tokens: torch.Size([10, 741])\nProcessing batch 10/906\nBatch tokens: torch.Size([10, 691])\nProcessing batch 11/906\nBatch tokens: torch.Size([10, 711])\nProcessing batch 12/906\nBatch tokens: torch.Size([10, 657])\nProcessing batch 13/906\nBatch tokens: torch.Size([10, 798])\nProcessing batch 14/906\nBatch tokens: torch.Size([10, 399])\nProcessing batch 15/906\nBatch tokens: torch.Size([10, 790])\nProcessing batch 16/906\nBatch tokens: torch.Size([10, 815])\nProcessing batch 17/906\nBatch tokens: torch.Size([10, 973])\nProcessing batch 18/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 19/906\nBatch tokens: torch.Size([10, 565])\nProcessing batch 20/906\nBatch tokens: torch.Size([10, 755])\nProcessing batch 21/906\nBatch tokens: torch.Size([10, 723])\nProcessing batch 22/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 23/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 24/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 25/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 26/906\nBatch tokens: torch.Size([10, 542])\nProcessing batch 27/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 28/906\nBatch tokens: torch.Size([10, 578])\nProcessing batch 29/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 30/906\nBatch tokens: torch.Size([10, 416])\nProcessing batch 31/906\nBatch tokens: torch.Size([10, 766])\nProcessing batch 32/906\nBatch tokens: torch.Size([10, 526])\nProcessing batch 33/906\nBatch tokens: torch.Size([10, 535])\nProcessing batch 34/906\nBatch tokens: torch.Size([10, 455])\nProcessing batch 35/906\nBatch tokens: torch.Size([10, 890])\nProcessing batch 36/906\nBatch tokens: torch.Size([10, 643])\nProcessing batch 37/906\nBatch tokens: torch.Size([10, 534])\nProcessing batch 38/906\nBatch tokens: torch.Size([10, 510])\nProcessing batch 39/906\nBatch tokens: torch.Size([10, 802])\nProcessing batch 40/906\nBatch tokens: torch.Size([10, 524])\nProcessing batch 41/906\nBatch tokens: torch.Size([10, 596])\nProcessing batch 42/906\nBatch tokens: torch.Size([10, 611])\nProcessing batch 43/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 44/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 45/906\nBatch tokens: torch.Size([10, 737])\nProcessing batch 46/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 47/906\nBatch tokens: torch.Size([10, 571])\nProcessing batch 48/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 49/906\nBatch tokens: torch.Size([10, 408])\nProcessing batch 50/906\nBatch tokens: torch.Size([10, 924])\nProcessing batch 51/906\nBatch tokens: torch.Size([10, 888])\nProcessing batch 52/906\nBatch tokens: torch.Size([10, 496])\nProcessing batch 53/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 54/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 55/906\nBatch tokens: torch.Size([10, 271])\nProcessing batch 56/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 57/906\nBatch tokens: torch.Size([10, 557])\nProcessing batch 58/906\nBatch tokens: torch.Size([10, 581])\nProcessing batch 59/906\nBatch tokens: torch.Size([10, 792])\nProcessing batch 60/906\nBatch tokens: torch.Size([10, 678])\nProcessing batch 61/906\nBatch tokens: torch.Size([10, 235])\nProcessing batch 62/906\nBatch tokens: torch.Size([10, 653])\nProcessing batch 63/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 64/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 65/906\nBatch tokens: torch.Size([10, 717])\nProcessing batch 66/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 67/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 68/906\nBatch tokens: torch.Size([10, 796])\nProcessing batch 69/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 70/906\nBatch tokens: torch.Size([10, 628])\nProcessing batch 71/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 72/906\nBatch tokens: torch.Size([10, 859])\nProcessing batch 73/906\nBatch tokens: torch.Size([10, 972])\nProcessing batch 74/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 75/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 76/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 77/906\nBatch tokens: torch.Size([10, 611])\nProcessing batch 78/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 79/906\nBatch tokens: torch.Size([10, 699])\nProcessing batch 80/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 81/906\nBatch tokens: torch.Size([10, 578])\nProcessing batch 82/906\nBatch tokens: torch.Size([10, 651])\nProcessing batch 83/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 84/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 85/906\nBatch tokens: torch.Size([10, 982])\nProcessing batch 86/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 87/906\nBatch tokens: torch.Size([10, 880])\nProcessing batch 88/906\nBatch tokens: torch.Size([10, 774])\nProcessing batch 89/906\nBatch tokens: torch.Size([10, 676])\nProcessing batch 90/906\nBatch tokens: torch.Size([10, 633])\nProcessing batch 91/906\nBatch tokens: torch.Size([10, 712])\nProcessing batch 92/906\nBatch tokens: torch.Size([10, 687])\nProcessing batch 93/906\nBatch tokens: torch.Size([10, 635])\nProcessing batch 94/906\nBatch tokens: torch.Size([10, 646])\nProcessing batch 95/906\nBatch tokens: torch.Size([10, 999])\nProcessing batch 96/906\nBatch tokens: torch.Size([10, 879])\nProcessing batch 97/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 98/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 99/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 100/906\nBatch tokens: torch.Size([10, 835])\nProcessing batch 101/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 102/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 103/906\nBatch tokens: torch.Size([10, 660])\nProcessing batch 104/906\nBatch tokens: torch.Size([10, 658])\nProcessing batch 105/906\nBatch tokens: torch.Size([10, 541])\nProcessing batch 106/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 107/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 108/906\nBatch tokens: torch.Size([10, 721])\nProcessing batch 109/906\nBatch tokens: torch.Size([10, 559])\nProcessing batch 110/906\nBatch tokens: torch.Size([10, 641])\nProcessing batch 111/906\nBatch tokens: torch.Size([10, 402])\nProcessing batch 112/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 113/906\nBatch tokens: torch.Size([10, 513])\nProcessing batch 114/906\nBatch tokens: torch.Size([10, 704])\nProcessing batch 115/906\nBatch tokens: torch.Size([10, 459])\nProcessing batch 116/906\nBatch tokens: torch.Size([10, 913])\nProcessing batch 117/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 118/906\nBatch tokens: torch.Size([10, 716])\nProcessing batch 119/906\nBatch tokens: torch.Size([10, 446])\nProcessing batch 120/906\nBatch tokens: torch.Size([10, 538])\nProcessing batch 121/906\nBatch tokens: torch.Size([10, 767])\nProcessing batch 122/906\nBatch tokens: torch.Size([10, 459])\nProcessing batch 123/906\nBatch tokens: torch.Size([10, 373])\nProcessing batch 124/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 125/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 126/906\nBatch tokens: torch.Size([10, 702])\nProcessing batch 127/906\nBatch tokens: torch.Size([10, 846])\nProcessing batch 128/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 129/906\nBatch tokens: torch.Size([10, 705])\nProcessing batch 130/906\nBatch tokens: torch.Size([10, 807])\nProcessing batch 131/906\nBatch tokens: torch.Size([10, 518])\nProcessing batch 132/906\nBatch tokens: torch.Size([10, 672])\nProcessing batch 133/906\nBatch tokens: torch.Size([10, 750])\nProcessing batch 134/906\nBatch tokens: torch.Size([10, 800])\nProcessing batch 135/906\nBatch tokens: torch.Size([10, 795])\nProcessing batch 136/906\nBatch tokens: torch.Size([10, 518])\nProcessing batch 137/906\nBatch tokens: torch.Size([10, 371])\nProcessing batch 138/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 139/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 140/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 141/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 142/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 143/906\nBatch tokens: torch.Size([10, 531])\nProcessing batch 144/906\nBatch tokens: torch.Size([10, 521])\nProcessing batch 145/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 146/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 147/906\nBatch tokens: torch.Size([10, 612])\nProcessing batch 148/906\nBatch tokens: torch.Size([10, 409])\nProcessing batch 149/906\nBatch tokens: torch.Size([10, 965])\nProcessing batch 150/906\nBatch tokens: torch.Size([10, 890])\nProcessing batch 151/906\nBatch tokens: torch.Size([10, 595])\nProcessing batch 152/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 153/906\nBatch tokens: torch.Size([10, 746])\nProcessing batch 154/906\nBatch tokens: torch.Size([10, 485])\nProcessing batch 155/906\nBatch tokens: torch.Size([10, 464])\nProcessing batch 156/906\nBatch tokens: torch.Size([10, 878])\nProcessing batch 157/906\nBatch tokens: torch.Size([10, 999])\nProcessing batch 158/906\nBatch tokens: torch.Size([10, 726])\nProcessing batch 159/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 160/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 161/906\nBatch tokens: torch.Size([10, 886])\nProcessing batch 162/906\nBatch tokens: torch.Size([10, 785])\nProcessing batch 163/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 164/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 165/906\nBatch tokens: torch.Size([10, 599])\nProcessing batch 166/906\nBatch tokens: torch.Size([10, 481])\nProcessing batch 167/906\nBatch tokens: torch.Size([10, 919])\nProcessing batch 168/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 169/906\nBatch tokens: torch.Size([10, 480])\nProcessing batch 170/906\nBatch tokens: torch.Size([10, 354])\nProcessing batch 171/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 172/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 173/906\nBatch tokens: torch.Size([10, 360])\nProcessing batch 174/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 175/906\nBatch tokens: torch.Size([10, 517])\nProcessing batch 176/906\nBatch tokens: torch.Size([10, 951])\nProcessing batch 177/906\nBatch tokens: torch.Size([10, 382])\nProcessing batch 178/906\nBatch tokens: torch.Size([10, 612])\nProcessing batch 179/906\nBatch tokens: torch.Size([10, 555])\nProcessing batch 180/906\nBatch tokens: torch.Size([10, 496])\nProcessing batch 181/906\nBatch tokens: torch.Size([10, 535])\nProcessing batch 182/906\nBatch tokens: torch.Size([10, 541])\nProcessing batch 183/906\nBatch tokens: torch.Size([10, 687])\nProcessing batch 184/906\nBatch tokens: torch.Size([10, 609])\nProcessing batch 185/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 186/906\nBatch tokens: torch.Size([10, 866])\nProcessing batch 187/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 188/906\nBatch tokens: torch.Size([10, 868])\nProcessing batch 189/906\nBatch tokens: torch.Size([10, 867])\nProcessing batch 190/906\nBatch tokens: torch.Size([10, 772])\nProcessing batch 191/906\nBatch tokens: torch.Size([10, 963])\nProcessing batch 192/906\nBatch tokens: torch.Size([10, 563])\nProcessing batch 193/906\nBatch tokens: torch.Size([10, 801])\nProcessing batch 194/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 195/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 196/906\nBatch tokens: torch.Size([10, 248])\nProcessing batch 197/906\nBatch tokens: torch.Size([10, 465])\nProcessing batch 198/906\nBatch tokens: torch.Size([10, 614])\nProcessing batch 199/906\nBatch tokens: torch.Size([10, 802])\nProcessing batch 200/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 201/906\nBatch tokens: torch.Size([10, 834])\nProcessing batch 202/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 203/906\nBatch tokens: torch.Size([10, 497])\nProcessing batch 204/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 205/906\nBatch tokens: torch.Size([10, 624])\nProcessing batch 206/906\nBatch tokens: torch.Size([10, 930])\nProcessing batch 207/906\nBatch tokens: torch.Size([10, 621])\nProcessing batch 208/906\nBatch tokens: torch.Size([10, 611])\nProcessing batch 209/906\nBatch tokens: torch.Size([10, 808])\nProcessing batch 210/906\nBatch tokens: torch.Size([10, 344])\nProcessing batch 211/906\nBatch tokens: torch.Size([10, 479])\nProcessing batch 212/906\nBatch tokens: torch.Size([10, 766])\nProcessing batch 213/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 214/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 215/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 216/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 217/906\nBatch tokens: torch.Size([10, 875])\nProcessing batch 218/906\nBatch tokens: torch.Size([10, 953])\nProcessing batch 219/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 220/906\nBatch tokens: torch.Size([10, 371])\nProcessing batch 221/906\nBatch tokens: torch.Size([10, 614])\nProcessing batch 222/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 223/906\nBatch tokens: torch.Size([10, 589])\nProcessing batch 224/906\nBatch tokens: torch.Size([10, 686])\nProcessing batch 225/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 226/906\nBatch tokens: torch.Size([10, 795])\nProcessing batch 227/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 228/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 229/906\nBatch tokens: torch.Size([10, 629])\nProcessing batch 230/906\nBatch tokens: torch.Size([10, 468])\nProcessing batch 231/906\nBatch tokens: torch.Size([10, 750])\nProcessing batch 232/906\nBatch tokens: torch.Size([10, 671])\nProcessing batch 233/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 234/906\nBatch tokens: torch.Size([10, 470])\nProcessing batch 235/906\nBatch tokens: torch.Size([10, 554])\nProcessing batch 236/906\nBatch tokens: torch.Size([10, 401])\nProcessing batch 237/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 238/906\nBatch tokens: torch.Size([10, 567])\nProcessing batch 239/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 240/906\nBatch tokens: torch.Size([10, 612])\nProcessing batch 241/906\nBatch tokens: torch.Size([10, 916])\nProcessing batch 242/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 243/906\nBatch tokens: torch.Size([10, 875])\nProcessing batch 244/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 245/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 246/906\nBatch tokens: torch.Size([10, 602])\nProcessing batch 247/906\nBatch tokens: torch.Size([10, 701])\nProcessing batch 248/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 249/906\nBatch tokens: torch.Size([10, 759])\nProcessing batch 250/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 251/906\nBatch tokens: torch.Size([10, 799])\nProcessing batch 252/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 253/906\nBatch tokens: torch.Size([10, 689])\nProcessing batch 254/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 255/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 256/906\nBatch tokens: torch.Size([10, 622])\nProcessing batch 257/906\nBatch tokens: torch.Size([10, 430])\nProcessing batch 258/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 259/906\nBatch tokens: torch.Size([10, 904])\nProcessing batch 260/906\nBatch tokens: torch.Size([10, 354])\nProcessing batch 261/906\nBatch tokens: torch.Size([10, 912])\nProcessing batch 262/906\nBatch tokens: torch.Size([10, 875])\nProcessing batch 263/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 264/906\nBatch tokens: torch.Size([10, 778])\nProcessing batch 265/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 266/906\nBatch tokens: torch.Size([10, 612])\nProcessing batch 267/906\nBatch tokens: torch.Size([10, 810])\nProcessing batch 268/906\nBatch tokens: torch.Size([10, 982])\nProcessing batch 269/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 270/906\nBatch tokens: torch.Size([10, 686])\nProcessing batch 271/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 272/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 273/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 274/906\nBatch tokens: torch.Size([10, 821])\nProcessing batch 275/906\nBatch tokens: torch.Size([10, 435])\nProcessing batch 276/906\nBatch tokens: torch.Size([10, 641])\nProcessing batch 277/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 278/906\nBatch tokens: torch.Size([10, 708])\nProcessing batch 279/906\nBatch tokens: torch.Size([10, 574])\nProcessing batch 280/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 281/906\nBatch tokens: torch.Size([10, 645])\nProcessing batch 282/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 283/906\nBatch tokens: torch.Size([10, 436])\nProcessing batch 284/906\nBatch tokens: torch.Size([10, 917])\nProcessing batch 285/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 286/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 287/906\nBatch tokens: torch.Size([10, 643])\nProcessing batch 288/906\nBatch tokens: torch.Size([10, 479])\nProcessing batch 289/906\nBatch tokens: torch.Size([10, 927])\nProcessing batch 290/906\nBatch tokens: torch.Size([10, 761])\nProcessing batch 291/906\nBatch tokens: torch.Size([10, 848])\nProcessing batch 292/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 293/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 294/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 295/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 296/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 297/906\nBatch tokens: torch.Size([10, 418])\nProcessing batch 298/906\nBatch tokens: torch.Size([10, 786])\nProcessing batch 299/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 300/906\nBatch tokens: torch.Size([10, 330])\nProcessing batch 301/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 302/906\nBatch tokens: torch.Size([10, 420])\nProcessing batch 303/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 304/906\nBatch tokens: torch.Size([10, 401])\nProcessing batch 305/906\nBatch tokens: torch.Size([10, 560])\nProcessing batch 306/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 307/906\nBatch tokens: torch.Size([10, 369])\nProcessing batch 308/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 309/906\nBatch tokens: torch.Size([10, 761])\nProcessing batch 310/906\nBatch tokens: torch.Size([10, 585])\nProcessing batch 311/906\nBatch tokens: torch.Size([10, 298])\nProcessing batch 312/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 313/906\nBatch tokens: torch.Size([10, 606])\nProcessing batch 314/906\nBatch tokens: torch.Size([10, 869])\nProcessing batch 315/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 316/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 317/906\nBatch tokens: torch.Size([10, 515])\nProcessing batch 318/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 319/906\nBatch tokens: torch.Size([10, 691])\nProcessing batch 320/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 321/906\nBatch tokens: torch.Size([10, 506])\nProcessing batch 322/906\nBatch tokens: torch.Size([10, 944])\nProcessing batch 323/906\nBatch tokens: torch.Size([10, 635])\nProcessing batch 324/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 325/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 326/906\nBatch tokens: torch.Size([10, 569])\nProcessing batch 327/906\nBatch tokens: torch.Size([10, 735])\nProcessing batch 328/906\nBatch tokens: torch.Size([10, 852])\nProcessing batch 329/906\nBatch tokens: torch.Size([10, 825])\nProcessing batch 330/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 331/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 332/906\nBatch tokens: torch.Size([10, 914])\nProcessing batch 333/906\nBatch tokens: torch.Size([10, 490])\nProcessing batch 334/906\nBatch tokens: torch.Size([10, 980])\nProcessing batch 335/906\nBatch tokens: torch.Size([10, 371])\nProcessing batch 336/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 337/906\nBatch tokens: torch.Size([10, 965])\nProcessing batch 338/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 339/906\nBatch tokens: torch.Size([10, 485])\nProcessing batch 340/906\nBatch tokens: torch.Size([10, 391])\nProcessing batch 341/906\nBatch tokens: torch.Size([10, 869])\nProcessing batch 342/906\nBatch tokens: torch.Size([10, 821])\nProcessing batch 343/906\nBatch tokens: torch.Size([10, 973])\nProcessing batch 344/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 345/906\nBatch tokens: torch.Size([10, 575])\nProcessing batch 346/906\nBatch tokens: torch.Size([10, 674])\nProcessing batch 347/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 348/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 349/906\nBatch tokens: torch.Size([10, 750])\nProcessing batch 350/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 351/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 352/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 353/906\nBatch tokens: torch.Size([10, 879])\nProcessing batch 354/906\nBatch tokens: torch.Size([10, 588])\nProcessing batch 355/906\nBatch tokens: torch.Size([10, 977])\nProcessing batch 356/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 357/906\nBatch tokens: torch.Size([10, 948])\nProcessing batch 358/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 359/906\nBatch tokens: torch.Size([10, 575])\nProcessing batch 360/906\nBatch tokens: torch.Size([10, 760])\nProcessing batch 361/906\nBatch tokens: torch.Size([10, 955])\nProcessing batch 362/906\nBatch tokens: torch.Size([10, 740])\nProcessing batch 363/906\nBatch tokens: torch.Size([10, 788])\nProcessing batch 364/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 365/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 366/906\nBatch tokens: torch.Size([10, 613])\nProcessing batch 367/906\nBatch tokens: torch.Size([10, 612])\nProcessing batch 368/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 369/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 370/906\nBatch tokens: torch.Size([10, 759])\nProcessing batch 371/906\nBatch tokens: torch.Size([10, 378])\nProcessing batch 372/906\nBatch tokens: torch.Size([10, 882])\nProcessing batch 373/906\nBatch tokens: torch.Size([10, 609])\nProcessing batch 374/906\nBatch tokens: torch.Size([10, 846])\nProcessing batch 375/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 376/906\nBatch tokens: torch.Size([10, 720])\nProcessing batch 377/906\nBatch tokens: torch.Size([10, 403])\nProcessing batch 378/906\nBatch tokens: torch.Size([10, 448])\nProcessing batch 379/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 380/906\nBatch tokens: torch.Size([10, 542])\nProcessing batch 381/906\nBatch tokens: torch.Size([10, 855])\nProcessing batch 382/906\nBatch tokens: torch.Size([10, 629])\nProcessing batch 383/906\nBatch tokens: torch.Size([10, 534])\nProcessing batch 384/906\nBatch tokens: torch.Size([10, 741])\nProcessing batch 385/906\nBatch tokens: torch.Size([10, 845])\nProcessing batch 386/906\nBatch tokens: torch.Size([10, 640])\nProcessing batch 387/906\nBatch tokens: torch.Size([10, 501])\nProcessing batch 388/906\nBatch tokens: torch.Size([10, 702])\nProcessing batch 389/906\nBatch tokens: torch.Size([10, 693])\nProcessing batch 390/906\nBatch tokens: torch.Size([10, 626])\nProcessing batch 391/906\nBatch tokens: torch.Size([10, 378])\nProcessing batch 392/906\nBatch tokens: torch.Size([10, 893])\nProcessing batch 393/906\nBatch tokens: torch.Size([10, 592])\nProcessing batch 394/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 395/906\nBatch tokens: torch.Size([10, 478])\nProcessing batch 396/906\nBatch tokens: torch.Size([10, 624])\nProcessing batch 397/906\nBatch tokens: torch.Size([10, 480])\nProcessing batch 398/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 399/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 400/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 401/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 402/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 403/906\nBatch tokens: torch.Size([10, 792])\nProcessing batch 404/906\nBatch tokens: torch.Size([10, 347])\nProcessing batch 405/906\nBatch tokens: torch.Size([10, 846])\nProcessing batch 406/906\nBatch tokens: torch.Size([10, 761])\nProcessing batch 407/906\nBatch tokens: torch.Size([10, 603])\nProcessing batch 408/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 409/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 410/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 411/906\nBatch tokens: torch.Size([10, 595])\nProcessing batch 412/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 413/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 414/906\nBatch tokens: torch.Size([10, 513])\nProcessing batch 415/906\nBatch tokens: torch.Size([10, 634])\nProcessing batch 416/906\nBatch tokens: torch.Size([10, 469])\nProcessing batch 417/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 418/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 419/906\nBatch tokens: torch.Size([10, 747])\nProcessing batch 420/906\nBatch tokens: torch.Size([10, 277])\nProcessing batch 421/906\nBatch tokens: torch.Size([10, 687])\nProcessing batch 422/906\nBatch tokens: torch.Size([10, 663])\nProcessing batch 423/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 424/906\nBatch tokens: torch.Size([10, 1002])\nProcessing batch 425/906\nBatch tokens: torch.Size([10, 611])\nProcessing batch 426/906\nBatch tokens: torch.Size([10, 965])\nProcessing batch 427/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 428/906\nBatch tokens: torch.Size([10, 880])\nProcessing batch 429/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 430/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 431/906\nBatch tokens: torch.Size([10, 370])\nProcessing batch 432/906\nBatch tokens: torch.Size([10, 655])\nProcessing batch 433/906\nBatch tokens: torch.Size([10, 433])\nProcessing batch 434/906\nBatch tokens: torch.Size([10, 470])\nProcessing batch 435/906\nBatch tokens: torch.Size([10, 936])\nProcessing batch 436/906\nBatch tokens: torch.Size([10, 792])\nProcessing batch 437/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 438/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 439/906\nBatch tokens: torch.Size([10, 768])\nProcessing batch 440/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 441/906\nBatch tokens: torch.Size([10, 935])\nProcessing batch 442/906\nBatch tokens: torch.Size([10, 488])\nProcessing batch 443/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 444/906\nBatch tokens: torch.Size([10, 822])\nProcessing batch 445/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 446/906\nBatch tokens: torch.Size([10, 763])\nProcessing batch 447/906\nBatch tokens: torch.Size([10, 814])\nProcessing batch 448/906\nBatch tokens: torch.Size([10, 837])\nProcessing batch 449/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 450/906\nBatch tokens: torch.Size([10, 762])\nProcessing batch 451/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 452/906\nBatch tokens: torch.Size([10, 616])\nProcessing batch 453/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 454/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 455/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 456/906\nBatch tokens: torch.Size([10, 824])\nProcessing batch 457/906\nBatch tokens: torch.Size([10, 614])\nProcessing batch 458/906\nBatch tokens: torch.Size([10, 877])\nProcessing batch 459/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 460/906\nBatch tokens: torch.Size([10, 603])\nProcessing batch 461/906\nBatch tokens: torch.Size([10, 569])\nProcessing batch 462/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 463/906\nBatch tokens: torch.Size([10, 907])\nProcessing batch 464/906\nBatch tokens: torch.Size([10, 533])\nProcessing batch 465/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 466/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 467/906\nBatch tokens: torch.Size([10, 874])\nProcessing batch 468/906\nBatch tokens: torch.Size([10, 449])\nProcessing batch 469/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 470/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 471/906\nBatch tokens: torch.Size([10, 760])\nProcessing batch 472/906\nBatch tokens: torch.Size([10, 441])\nProcessing batch 473/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 474/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 475/906\nBatch tokens: torch.Size([10, 904])\nProcessing batch 476/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 477/906\nBatch tokens: torch.Size([10, 625])\nProcessing batch 478/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 479/906\nBatch tokens: torch.Size([10, 428])\nProcessing batch 480/906\nBatch tokens: torch.Size([10, 506])\nProcessing batch 481/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 482/906\nBatch tokens: torch.Size([10, 780])\nProcessing batch 483/906\nBatch tokens: torch.Size([10, 839])\nProcessing batch 484/906\nBatch tokens: torch.Size([10, 885])\nProcessing batch 485/906\nBatch tokens: torch.Size([10, 390])\nProcessing batch 486/906\nBatch tokens: torch.Size([10, 967])\nProcessing batch 487/906\nBatch tokens: torch.Size([10, 702])\nProcessing batch 488/906\nBatch tokens: torch.Size([10, 987])\nProcessing batch 489/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 490/906\nBatch tokens: torch.Size([10, 634])\nProcessing batch 491/906\nBatch tokens: torch.Size([10, 651])\nProcessing batch 492/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 493/906\nBatch tokens: torch.Size([10, 410])\nProcessing batch 494/906\nBatch tokens: torch.Size([10, 784])\nProcessing batch 495/906\nBatch tokens: torch.Size([10, 552])\nProcessing batch 496/906\nBatch tokens: torch.Size([10, 513])\nProcessing batch 497/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 498/906\nBatch tokens: torch.Size([10, 761])\nProcessing batch 499/906\nBatch tokens: torch.Size([10, 494])\nProcessing batch 500/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 501/906\nBatch tokens: torch.Size([10, 668])\nProcessing batch 502/906\nBatch tokens: torch.Size([10, 987])\nProcessing batch 503/906\nBatch tokens: torch.Size([10, 536])\nProcessing batch 504/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 505/906\nBatch tokens: torch.Size([10, 837])\nProcessing batch 506/906\nBatch tokens: torch.Size([10, 784])\nProcessing batch 507/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 508/906\nBatch tokens: torch.Size([10, 953])\nProcessing batch 509/906\nBatch tokens: torch.Size([10, 277])\nProcessing batch 510/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 511/906\nBatch tokens: torch.Size([10, 786])\nProcessing batch 512/906\nBatch tokens: torch.Size([10, 559])\nProcessing batch 513/906\nBatch tokens: torch.Size([10, 908])\nProcessing batch 514/906\nBatch tokens: torch.Size([10, 774])\nProcessing batch 515/906\nBatch tokens: torch.Size([10, 995])\nProcessing batch 516/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 517/906\nBatch tokens: torch.Size([10, 439])\nProcessing batch 518/906\nBatch tokens: torch.Size([10, 890])\nProcessing batch 519/906\nBatch tokens: torch.Size([10, 513])\nProcessing batch 520/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 521/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 522/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 523/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 524/906\nBatch tokens: torch.Size([10, 819])\nProcessing batch 525/906\nBatch tokens: torch.Size([10, 664])\nProcessing batch 526/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 527/906\nBatch tokens: torch.Size([10, 971])\nProcessing batch 528/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 529/906\nBatch tokens: torch.Size([10, 828])\nProcessing batch 530/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 531/906\nBatch tokens: torch.Size([10, 955])\nProcessing batch 532/906\nBatch tokens: torch.Size([10, 887])\nProcessing batch 533/906\nBatch tokens: torch.Size([10, 503])\nProcessing batch 534/906\nBatch tokens: torch.Size([10, 895])\nProcessing batch 535/906\nBatch tokens: torch.Size([10, 601])\nProcessing batch 536/906\nBatch tokens: torch.Size([10, 408])\nProcessing batch 537/906\nBatch tokens: torch.Size([10, 698])\nProcessing batch 538/906\nBatch tokens: torch.Size([10, 925])\nProcessing batch 539/906\nBatch tokens: torch.Size([10, 733])\nProcessing batch 540/906\nBatch tokens: torch.Size([10, 366])\nProcessing batch 541/906\nBatch tokens: torch.Size([10, 737])\nProcessing batch 542/906\nBatch tokens: torch.Size([10, 882])\nProcessing batch 543/906\nBatch tokens: torch.Size([10, 669])\nProcessing batch 544/906\nBatch tokens: torch.Size([10, 610])\nProcessing batch 545/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 546/906\nBatch tokens: torch.Size([10, 730])\nProcessing batch 547/906\nBatch tokens: torch.Size([10, 447])\nProcessing batch 548/906\nBatch tokens: torch.Size([10, 507])\nProcessing batch 549/906\nBatch tokens: torch.Size([10, 628])\nProcessing batch 550/906\nBatch tokens: torch.Size([10, 911])\nProcessing batch 551/906\nBatch tokens: torch.Size([10, 692])\nProcessing batch 552/906\nBatch tokens: torch.Size([10, 833])\nProcessing batch 553/906\nBatch tokens: torch.Size([10, 501])\nProcessing batch 554/906\nBatch tokens: torch.Size([10, 974])\nProcessing batch 555/906\nBatch tokens: torch.Size([10, 598])\nProcessing batch 556/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 557/906\nBatch tokens: torch.Size([10, 731])\nProcessing batch 558/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 559/906\nBatch tokens: torch.Size([10, 830])\nProcessing batch 560/906\nBatch tokens: torch.Size([10, 771])\nProcessing batch 561/906\nBatch tokens: torch.Size([10, 877])\nProcessing batch 562/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 563/906\nBatch tokens: torch.Size([10, 515])\nProcessing batch 564/906\nBatch tokens: torch.Size([10, 720])\nProcessing batch 565/906\nBatch tokens: torch.Size([10, 503])\nProcessing batch 566/906\nBatch tokens: torch.Size([10, 853])\nProcessing batch 567/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 568/906\nBatch tokens: torch.Size([10, 888])\nProcessing batch 569/906\nBatch tokens: torch.Size([10, 743])\nProcessing batch 570/906\nBatch tokens: torch.Size([10, 378])\nProcessing batch 571/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 572/906\nBatch tokens: torch.Size([10, 407])\nProcessing batch 573/906\nBatch tokens: torch.Size([10, 583])\nProcessing batch 574/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 575/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 576/906\nBatch tokens: torch.Size([10, 249])\nProcessing batch 577/906\nBatch tokens: torch.Size([10, 403])\nProcessing batch 578/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 579/906\nBatch tokens: torch.Size([10, 330])\nProcessing batch 580/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 581/906\nBatch tokens: torch.Size([10, 517])\nProcessing batch 582/906\nBatch tokens: torch.Size([10, 765])\nProcessing batch 583/906\nBatch tokens: torch.Size([10, 732])\nProcessing batch 584/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 585/906\nBatch tokens: torch.Size([10, 828])\nProcessing batch 586/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 587/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 588/906\nBatch tokens: torch.Size([10, 388])\nProcessing batch 589/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 590/906\nBatch tokens: torch.Size([10, 874])\nProcessing batch 591/906\nBatch tokens: torch.Size([10, 576])\nProcessing batch 592/906\nBatch tokens: torch.Size([10, 537])\nProcessing batch 593/906\nBatch tokens: torch.Size([10, 488])\nProcessing batch 594/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 595/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 596/906\nBatch tokens: torch.Size([10, 979])\nProcessing batch 597/906\nBatch tokens: torch.Size([10, 570])\nProcessing batch 598/906\nBatch tokens: torch.Size([10, 547])\nProcessing batch 599/906\nBatch tokens: torch.Size([10, 768])\nProcessing batch 600/906\nBatch tokens: torch.Size([10, 480])\nProcessing batch 601/906\nBatch tokens: torch.Size([10, 970])\nProcessing batch 602/906\nBatch tokens: torch.Size([10, 807])\nProcessing batch 603/906\nBatch tokens: torch.Size([10, 374])\nProcessing batch 604/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 605/906\nBatch tokens: torch.Size([10, 564])\nProcessing batch 606/906\nBatch tokens: torch.Size([10, 420])\nProcessing batch 607/906\nBatch tokens: torch.Size([10, 495])\nProcessing batch 608/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 609/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 610/906\nBatch tokens: torch.Size([10, 558])\nProcessing batch 611/906\nBatch tokens: torch.Size([10, 713])\nProcessing batch 612/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 613/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 614/906\nBatch tokens: torch.Size([10, 602])\nProcessing batch 615/906\nBatch tokens: torch.Size([10, 808])\nProcessing batch 616/906\nBatch tokens: torch.Size([10, 818])\nProcessing batch 617/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 618/906\nBatch tokens: torch.Size([10, 776])\nProcessing batch 619/906\nBatch tokens: torch.Size([10, 569])\nProcessing batch 620/906\nBatch tokens: torch.Size([10, 524])\nProcessing batch 621/906\nBatch tokens: torch.Size([10, 788])\nProcessing batch 622/906\nBatch tokens: torch.Size([10, 696])\nProcessing batch 623/906\nBatch tokens: torch.Size([10, 515])\nProcessing batch 624/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 625/906\nBatch tokens: torch.Size([10, 919])\nProcessing batch 626/906\nBatch tokens: torch.Size([10, 541])\nProcessing batch 627/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 628/906\nBatch tokens: torch.Size([10, 338])\nProcessing batch 629/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 630/906\nBatch tokens: torch.Size([10, 924])\nProcessing batch 631/906\nBatch tokens: torch.Size([10, 784])\nProcessing batch 632/906\nBatch tokens: torch.Size([10, 743])\nProcessing batch 633/906\nBatch tokens: torch.Size([10, 506])\nProcessing batch 634/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 635/906\nBatch tokens: torch.Size([10, 651])\nProcessing batch 636/906\nBatch tokens: torch.Size([10, 757])\nProcessing batch 637/906\nBatch tokens: torch.Size([10, 643])\nProcessing batch 638/906\nBatch tokens: torch.Size([10, 615])\nProcessing batch 639/906\nBatch tokens: torch.Size([10, 614])\nProcessing batch 640/906\nBatch tokens: torch.Size([10, 467])\nProcessing batch 641/906\nBatch tokens: torch.Size([10, 421])\nProcessing batch 642/906\nBatch tokens: torch.Size([10, 929])\nProcessing batch 643/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 644/906\nBatch tokens: torch.Size([10, 616])\nProcessing batch 645/906\nBatch tokens: torch.Size([10, 750])\nProcessing batch 646/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 647/906\nBatch tokens: torch.Size([10, 539])\nProcessing batch 648/906\nBatch tokens: torch.Size([10, 593])\nProcessing batch 649/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 650/906\nBatch tokens: torch.Size([10, 673])\nProcessing batch 651/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 652/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 653/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 654/906\nBatch tokens: torch.Size([10, 703])\nProcessing batch 655/906\nBatch tokens: torch.Size([10, 739])\nProcessing batch 656/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 657/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 658/906\nBatch tokens: torch.Size([10, 675])\nProcessing batch 659/906\nBatch tokens: torch.Size([10, 862])\nProcessing batch 660/906\nBatch tokens: torch.Size([10, 748])\nProcessing batch 661/906\nBatch tokens: torch.Size([10, 771])\nProcessing batch 662/906\nBatch tokens: torch.Size([10, 659])\nProcessing batch 663/906\nBatch tokens: torch.Size([10, 299])\nProcessing batch 664/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 665/906\nBatch tokens: torch.Size([10, 964])\nProcessing batch 666/906\nBatch tokens: torch.Size([10, 952])\nProcessing batch 667/906\nBatch tokens: torch.Size([10, 764])\nProcessing batch 668/906\nBatch tokens: torch.Size([10, 420])\nProcessing batch 669/906\nBatch tokens: torch.Size([10, 569])\nProcessing batch 670/906\nBatch tokens: torch.Size([10, 411])\nProcessing batch 671/906\nBatch tokens: torch.Size([10, 887])\nProcessing batch 672/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 673/906\nBatch tokens: torch.Size([10, 435])\nProcessing batch 674/906\nBatch tokens: torch.Size([10, 527])\nProcessing batch 675/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 676/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 677/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 678/906\nBatch tokens: torch.Size([10, 807])\nProcessing batch 679/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 680/906\nBatch tokens: torch.Size([10, 389])\nProcessing batch 681/906\nBatch tokens: torch.Size([10, 462])\nProcessing batch 682/906\nBatch tokens: torch.Size([10, 485])\nProcessing batch 683/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 684/906\nBatch tokens: torch.Size([10, 777])\nProcessing batch 685/906\nBatch tokens: torch.Size([10, 672])\nProcessing batch 686/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 687/906\nBatch tokens: torch.Size([10, 366])\nProcessing batch 688/906\nBatch tokens: torch.Size([10, 572])\nProcessing batch 689/906\nBatch tokens: torch.Size([10, 393])\nProcessing batch 690/906\nBatch tokens: torch.Size([10, 757])\nProcessing batch 691/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 692/906\nBatch tokens: torch.Size([10, 584])\nProcessing batch 693/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 694/906\nBatch tokens: torch.Size([10, 562])\nProcessing batch 695/906\nBatch tokens: torch.Size([10, 725])\nProcessing batch 696/906\nBatch tokens: torch.Size([10, 275])\nProcessing batch 697/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 698/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 699/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 700/906\nBatch tokens: torch.Size([10, 515])\nProcessing batch 701/906\nBatch tokens: torch.Size([10, 537])\nProcessing batch 702/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 703/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 704/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 705/906\nBatch tokens: torch.Size([10, 631])\nProcessing batch 706/906\nBatch tokens: torch.Size([10, 708])\nProcessing batch 707/906\nBatch tokens: torch.Size([10, 376])\nProcessing batch 708/906\nBatch tokens: torch.Size([10, 886])\nProcessing batch 709/906\nBatch tokens: torch.Size([10, 583])\nProcessing batch 710/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 711/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 712/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 713/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 714/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 715/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 716/906\nBatch tokens: torch.Size([10, 498])\nProcessing batch 717/906\nBatch tokens: torch.Size([10, 543])\nProcessing batch 718/906\nBatch tokens: torch.Size([10, 834])\nProcessing batch 719/906\nBatch tokens: torch.Size([10, 918])\nProcessing batch 720/906\nBatch tokens: torch.Size([10, 519])\nProcessing batch 721/906\nBatch tokens: torch.Size([10, 382])\nProcessing batch 722/906\nBatch tokens: torch.Size([10, 482])\nProcessing batch 723/906\nBatch tokens: torch.Size([10, 510])\nProcessing batch 724/906\nBatch tokens: torch.Size([10, 379])\nProcessing batch 725/906\nBatch tokens: torch.Size([10, 589])\nProcessing batch 726/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 727/906\nBatch tokens: torch.Size([10, 746])\nProcessing batch 728/906\nBatch tokens: torch.Size([10, 809])\nProcessing batch 729/906\nBatch tokens: torch.Size([10, 595])\nProcessing batch 730/906\nBatch tokens: torch.Size([10, 271])\nProcessing batch 731/906\nBatch tokens: torch.Size([10, 431])\nProcessing batch 732/906\nBatch tokens: torch.Size([10, 507])\nProcessing batch 733/906\nBatch tokens: torch.Size([10, 739])\nProcessing batch 734/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 735/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 736/906\nBatch tokens: torch.Size([10, 627])\nProcessing batch 737/906\nBatch tokens: torch.Size([10, 518])\nProcessing batch 738/906\nBatch tokens: torch.Size([10, 495])\nProcessing batch 739/906\nBatch tokens: torch.Size([10, 907])\nProcessing batch 740/906\nBatch tokens: torch.Size([10, 942])\nProcessing batch 741/906\nBatch tokens: torch.Size([10, 689])\nProcessing batch 742/906\nBatch tokens: torch.Size([10, 454])\nProcessing batch 743/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 744/906\nBatch tokens: torch.Size([10, 999])\nProcessing batch 745/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 746/906\nBatch tokens: torch.Size([10, 334])\nProcessing batch 747/906\nBatch tokens: torch.Size([10, 685])\nProcessing batch 748/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 749/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 750/906\nBatch tokens: torch.Size([10, 895])\nProcessing batch 751/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 752/906\nBatch tokens: torch.Size([10, 490])\nProcessing batch 753/906\nBatch tokens: torch.Size([10, 387])\nProcessing batch 754/906\nBatch tokens: torch.Size([10, 466])\nProcessing batch 755/906\nBatch tokens: torch.Size([10, 706])\nProcessing batch 756/906\nBatch tokens: torch.Size([10, 705])\nProcessing batch 757/906\nBatch tokens: torch.Size([10, 929])\nProcessing batch 758/906\nBatch tokens: torch.Size([10, 807])\nProcessing batch 759/906\nBatch tokens: torch.Size([10, 530])\nProcessing batch 760/906\nBatch tokens: torch.Size([10, 458])\nProcessing batch 761/906\nBatch tokens: torch.Size([10, 760])\nProcessing batch 762/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 763/906\nBatch tokens: torch.Size([10, 477])\nProcessing batch 764/906\nBatch tokens: torch.Size([10, 774])\nProcessing batch 765/906\nBatch tokens: torch.Size([10, 483])\nProcessing batch 766/906\nBatch tokens: torch.Size([10, 521])\nProcessing batch 767/906\nBatch tokens: torch.Size([10, 551])\nProcessing batch 768/906\nBatch tokens: torch.Size([10, 716])\nProcessing batch 769/906\nBatch tokens: torch.Size([10, 401])\nProcessing batch 770/906\nBatch tokens: torch.Size([10, 908])\nProcessing batch 771/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 772/906\nBatch tokens: torch.Size([10, 953])\nProcessing batch 773/906\nBatch tokens: torch.Size([10, 619])\nProcessing batch 774/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 775/906\nBatch tokens: torch.Size([10, 421])\nProcessing batch 776/906\nBatch tokens: torch.Size([10, 601])\nProcessing batch 777/906\nBatch tokens: torch.Size([10, 469])\nProcessing batch 778/906\nBatch tokens: torch.Size([10, 494])\nProcessing batch 779/906\nBatch tokens: torch.Size([10, 993])\nProcessing batch 780/906\nBatch tokens: torch.Size([10, 834])\nProcessing batch 781/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 782/906\nBatch tokens: torch.Size([10, 904])\nProcessing batch 783/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 784/906\nBatch tokens: torch.Size([10, 617])\nProcessing batch 785/906\nBatch tokens: torch.Size([10, 635])\nProcessing batch 786/906\nBatch tokens: torch.Size([10, 571])\nProcessing batch 787/906\nBatch tokens: torch.Size([10, 997])\nProcessing batch 788/906\nBatch tokens: torch.Size([10, 485])\nProcessing batch 789/906\nBatch tokens: torch.Size([10, 351])\nProcessing batch 790/906\nBatch tokens: torch.Size([10, 592])\nProcessing batch 791/906\nBatch tokens: torch.Size([10, 712])\nProcessing batch 792/906\nBatch tokens: torch.Size([10, 346])\nProcessing batch 793/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 794/906\nBatch tokens: torch.Size([10, 769])\nProcessing batch 795/906\nBatch tokens: torch.Size([10, 665])\nProcessing batch 796/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 797/906\nBatch tokens: torch.Size([10, 504])\nProcessing batch 798/906\nBatch tokens: torch.Size([10, 953])\nProcessing batch 799/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 800/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 801/906\nBatch tokens: torch.Size([10, 378])\nProcessing batch 802/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 803/906\nBatch tokens: torch.Size([10, 367])\nProcessing batch 804/906\nBatch tokens: torch.Size([10, 361])\nProcessing batch 805/906\nBatch tokens: torch.Size([10, 408])\nProcessing batch 806/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 807/906\nBatch tokens: torch.Size([10, 552])\nProcessing batch 808/906\nBatch tokens: torch.Size([10, 603])\nProcessing batch 809/906\nBatch tokens: torch.Size([10, 518])\nProcessing batch 810/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 811/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 812/906\nBatch tokens: torch.Size([10, 477])\nProcessing batch 813/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 814/906\nBatch tokens: torch.Size([10, 426])\nProcessing batch 815/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 816/906\nBatch tokens: torch.Size([10, 808])\nProcessing batch 817/906\nBatch tokens: torch.Size([10, 979])\nProcessing batch 818/906\nBatch tokens: torch.Size([10, 882])\nProcessing batch 819/906\nBatch tokens: torch.Size([10, 790])\nProcessing batch 820/906\nBatch tokens: torch.Size([10, 379])\nProcessing batch 821/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 822/906\nBatch tokens: torch.Size([10, 834])\nProcessing batch 823/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 824/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 825/906\nBatch tokens: torch.Size([10, 749])\nProcessing batch 826/906\nBatch tokens: torch.Size([10, 731])\nProcessing batch 827/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 828/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 829/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 830/906\nBatch tokens: torch.Size([10, 767])\nProcessing batch 831/906\nBatch tokens: torch.Size([10, 542])\nProcessing batch 832/906\nBatch tokens: torch.Size([10, 734])\nProcessing batch 833/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 834/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 835/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 836/906\nBatch tokens: torch.Size([10, 888])\nProcessing batch 837/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 838/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 839/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 840/906\nBatch tokens: torch.Size([10, 725])\nProcessing batch 841/906\nBatch tokens: torch.Size([10, 725])\nProcessing batch 842/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 843/906\nBatch tokens: torch.Size([10, 763])\nProcessing batch 844/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 845/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 846/906\nBatch tokens: torch.Size([10, 831])\nProcessing batch 847/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 848/906\nBatch tokens: torch.Size([10, 671])\nProcessing batch 849/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 850/906\nBatch tokens: torch.Size([10, 930])\nProcessing batch 851/906\nBatch tokens: torch.Size([10, 1000])\nProcessing batch 852/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 853/906\nBatch tokens: torch.Size([10, 728])\nProcessing batch 854/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 855/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 856/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 857/906\nBatch tokens: torch.Size([10, 874])\nProcessing batch 858/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 859/906\nBatch tokens: torch.Size([10, 865])\nProcessing batch 860/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 861/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 862/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 863/906\nBatch tokens: torch.Size([10, 753])\nProcessing batch 864/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 865/906\nBatch tokens: torch.Size([10, 937])\nProcessing batch 866/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 867/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 868/906\nBatch tokens: torch.Size([10, 948])\nProcessing batch 869/906\nBatch tokens: torch.Size([10, 977])\nProcessing batch 870/906\nBatch tokens: torch.Size([10, 952])\nProcessing batch 871/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 872/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 873/906\nBatch tokens: torch.Size([10, 647])\nProcessing batch 874/906\nBatch tokens: torch.Size([10, 832])\nProcessing batch 875/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 876/906\nBatch tokens: torch.Size([10, 953])\nProcessing batch 877/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 878/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 879/906\nBatch tokens: torch.Size([10, 881])\nProcessing batch 880/906\nBatch tokens: torch.Size([10, 530])\nProcessing batch 881/906\nBatch tokens: torch.Size([10, 617])\nProcessing batch 882/906\nBatch tokens: torch.Size([10, 744])\nProcessing batch 883/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 884/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 885/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 886/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 887/906\nBatch tokens: torch.Size([10, 560])\nProcessing batch 888/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 889/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 890/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 891/906\nBatch tokens: torch.Size([10, 907])\nProcessing batch 892/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 893/906\nBatch tokens: torch.Size([10, 797])\nProcessing batch 894/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 895/906\nBatch tokens: torch.Size([10, 723])\nProcessing batch 896/906\nBatch tokens: torch.Size([10, 803])\nProcessing batch 897/906\nBatch tokens: torch.Size([10, 735])\nProcessing batch 898/906\nBatch tokens: torch.Size([10, 594])\nProcessing batch 899/906\nBatch tokens: torch.Size([10, 910])\nProcessing batch 900/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 901/906\nBatch tokens: torch.Size([10, 774])\nProcessing batch 902/906\nBatch tokens: torch.Size([10, 938])\nProcessing batch 903/906\nBatch tokens: torch.Size([10, 506])\nProcessing batch 904/906\nBatch tokens: torch.Size([10, 925])\nProcessing batch 905/906\nBatch tokens: torch.Size([10, 1004])\nProcessing batch 906/906\nBatch tokens: torch.Size([6, 387])\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Load the embeddings\nembedding_df = pd.read_csv('/kaggle/working/embeddings_protien.csv')\n\n# Split the data into features and labels\nX = embedding_df.drop(columns=['label'])\ny = embedding_df['label']\n\n# Split the data into training (60%) and testing (40%) sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n# Save the split datasets\nX_train.to_csv('/kaggle/working/X_train_pro.csv', index=False)\nX_test.to_csv('/kaggle/working/X_test_pro.csv', index=False)\ny_train.to_csv('/kaggle/working/y_train_pro.csv', index=False)\ny_test.to_csv('/kaggle/working/y_test_pro.csv', index=False)\nX_val.to_csv('/kaggle/working/X_val_pro.csv', index=False)\ny_val.to_csv('/kaggle/working/y_val_pro.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:32:00.844527Z","iopub.execute_input":"2024-09-26T17:32:00.844829Z","iopub.status.idle":"2024-09-26T17:32:20.577007Z","shell.execute_reply.started":"2024-09-26T17:32:00.844803Z","shell.execute_reply":"2024-09-26T17:32:20.576249Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from lazypredict.Supervised import LazyClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load the split datasets\nX_train = pd.read_csv('/kaggle/working/X_train_pro.csv')\nX_test = pd.read_csv('/kaggle/working/X_test_pro.csv')\nX_val = pd.read_csv('/kaggle/working/X_val_pro.csv')\ny_train = pd.read_csv('/kaggle/working/y_train_pro.csv').values.ravel()\ny_test = pd.read_csv('/kaggle/working/y_test_pro.csv').values.ravel()\ny_val = pd.read_csv('/kaggle/working/y_val_pro.csv').values.ravel()\n\n# Initialize LazyClassifier\nclf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n\n# Train and test the models\nmodels, predictions = clf.fit(X_train, X_val, y_train, y_val)\n\n# Display the results\nprint(models)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:32:20.579057Z","iopub.execute_input":"2024-09-26T17:32:20.579355Z","iopub.status.idle":"2024-09-26T17:36:27.283997Z","shell.execute_reply.started":"2024-09-26T17:32:20.579330Z","shell.execute_reply":"2024-09-26T17:36:27.283156Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [03:46<00:04,  4.84s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 2053, number of negative: 3380\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067080 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 326400\n[LightGBM] [Info] Number of data points in the train set: 5433, number of used features: 1280\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.377876 -> initscore=-0.498574\n[LightGBM] [Info] Start training from score -0.498574\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [03:59<00:00,  8.27s/it]","output_type":"stream"},{"name":"stdout","text":"                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nXGBClassifier                      0.97               0.97     0.97      0.97   \nLogisticRegression                 0.97               0.97     0.97      0.97   \nSVC                                0.97               0.97     0.97      0.97   \nSGDClassifier                      0.97               0.96     0.96      0.97   \nKNeighborsClassifier               0.96               0.96     0.96      0.96   \nLGBMClassifier                     0.97               0.96     0.96      0.97   \nRidgeClassifierCV                  0.96               0.96     0.96      0.96   \nLinearDiscriminantAnalysis         0.96               0.96     0.96      0.96   \nRidgeClassifier                    0.96               0.96     0.96      0.96   \nExtraTreesClassifier               0.97               0.96     0.96      0.97   \nPassiveAggressiveClassifier        0.96               0.96     0.96      0.96   \nRandomForestClassifier             0.96               0.96     0.96      0.96   \nCalibratedClassifierCV             0.96               0.96     0.96      0.96   \nAdaBoostClassifier                 0.96               0.96     0.96      0.96   \nLinearSVC                          0.95               0.96     0.96      0.95   \nPerceptron                         0.96               0.96     0.96      0.96   \nBaggingClassifier                  0.96               0.95     0.95      0.96   \nDecisionTreeClassifier             0.93               0.93     0.93      0.93   \nExtraTreeClassifier                0.93               0.92     0.92      0.93   \nNuSVC                              0.91               0.89     0.89      0.91   \nGaussianNB                         0.90               0.89     0.89      0.90   \nNearestCentroid                    0.88               0.89     0.89      0.88   \nBernoulliNB                        0.88               0.88     0.88      0.88   \nQuadraticDiscriminantAnalysis      0.87               0.82     0.82      0.86   \nLabelPropagation                   0.79               0.70     0.70      0.76   \nLabelSpreading                     0.79               0.70     0.70      0.76   \nDummyClassifier                    0.64               0.50     0.50      0.50   \n\n                               Time Taken  \nModel                                      \nXGBClassifier                       11.48  \nLogisticRegression                   0.96  \nSVC                                  5.34  \nSGDClassifier                        1.00  \nKNeighborsClassifier                 0.75  \nLGBMClassifier                      13.46  \nRidgeClassifierCV                    2.19  \nLinearDiscriminantAnalysis           2.14  \nRidgeClassifier                      0.69  \nExtraTreesClassifier                 2.22  \nPassiveAggressiveClassifier          0.83  \nRandomForestClassifier              16.99  \nCalibratedClassifierCV              13.66  \nAdaBoostClassifier                  45.20  \nLinearSVC                            3.44  \nPerceptron                           0.66  \nBaggingClassifier                   75.75  \nDecisionTreeClassifier              12.76  \nExtraTreeClassifier                  0.34  \nNuSVC                               20.80  \nGaussianNB                           0.43  \nNearestCentroid                      0.42  \nBernoulliNB                          0.60  \nQuadraticDiscriminantAnalysis        3.35  \nLabelPropagation                     1.72  \nLabelSpreading                       2.01  \nDummyClassifier                      0.31  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\n# Define the model dictionary including the specified models\nmodel_dict = {\n    'XGBClassifier': XGBClassifier(),\n    'LGBMClassifier': LGBMClassifier(),\n    'ExtraTreesClassifier': ExtraTreesClassifier(),\n    'SVC': SVC(),\n    'RandomForestClassifier': RandomForestClassifier(),\n}\n\n# Fit and evaluate each model\nbest_model_name = None\nbest_accuracy = 0\n\nfor model_name, model in model_dict.items():\n    model.fit(X_train, y_train)\n    val_predictions = model.predict(X_val)\n    test_predictions = model.predict(X_test)\n    val_accuracy = accuracy_score(y_val, val_predictions)\n    test_accuracy = accuracy_score(y_test, test_predictions)\n    print(f\"{model_name} validation accuracy: {val_accuracy:.4f}, test accuracy: {test_accuracy:.4f}\")\n\n    if val_accuracy > best_accuracy:\n        best_accuracy = val_accuracy\n        best_model_name = model_name\n\nprint(f\"\\nBest Model Name: {best_model_name}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:36:27.285226Z","iopub.execute_input":"2024-09-26T17:36:27.285522Z","iopub.status.idle":"2024-09-26T17:37:19.464406Z","shell.execute_reply.started":"2024-09-26T17:36:27.285490Z","shell.execute_reply":"2024-09-26T17:37:19.463438Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"XGBClassifier validation accuracy: 0.9691, test accuracy: 0.9763\n[LightGBM] [Info] Number of positive: 2053, number of negative: 3380\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070243 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 326400\n[LightGBM] [Info] Number of data points in the train set: 5433, number of used features: 1280\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.377876 -> initscore=-0.498574\n[LightGBM] [Info] Start training from score -0.498574\nLGBMClassifier validation accuracy: 0.9647, test accuracy: 0.9768\nExtraTreesClassifier validation accuracy: 0.9663, test accuracy: 0.9774\nSVC validation accuracy: 0.9431, test accuracy: 0.9432\nRandomForestClassifier validation accuracy: 0.9641, test accuracy: 0.9752\n\nBest Model Name: XGBClassifier\n","output_type":"stream"}]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, roc_auc_score, precision_recall_curve, auc, confusion_matrix, classification_report\n\n# Define the model dictionary including AdaBoostClassifier\nmodel_dict = {\n    'LGBMClassifier': LGBMClassifier(),\n    'XGBClassifier': XGBClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'AdaBoostClassifier': AdaBoostClassifier(),\n    'LogisticRegression': LogisticRegression(),\n    'SVC': SVC(probability=True),  # SVC needs probability=True for AUROC\n    'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n    'ExtraTreesClassifier':ExtraTreesClassifier(),\n}\n\n# Function to calculate additional metrics\ndef calculate_metrics(y_true, y_pred, y_prob=None):\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    mcc = matthews_corrcoef(y_true, y_pred)\n    \n    sensitivity = tp / (tp + fn)  # Sensitivity (SN)\n    specificity = tn / (tn + fp)  # Specificity (SP)\n    fdr = fp / (fp + tp)  # False Discovery Rate (FDR)\n    \n    if y_prob is not None:\n        auroc = roc_auc_score(y_true, y_prob[:, 1])\n        precision, recall, _ = precision_recall_curve(y_true, y_prob[:, 1])\n        auprc = auc(recall, precision)\n    else:\n        auroc = None\n        auprc = None\n\n    return {\n        'accuracy': accuracy,\n        'f1_score': f1,\n        'mcc': mcc,\n        'sensitivity': sensitivity,\n        'specificity': specificity,\n        'fdr': fdr,\n        'auroc': auroc,\n        'auprc': auprc\n    }\n\n# Fit and evaluate each model\nbest_model_name = None\nbest_accuracy = 0\nresults = {}\n\nfor model_name, model in model_dict.items():\n    # Fit the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions\n    val_predictions = model.predict(X_val)\n    test_predictions = model.predict(X_test)\n    \n    # Probability predictions for ROC and AUPRC\n    if hasattr(model, \"predict_proba\"):\n        val_prob = model.predict_proba(X_val)\n        test_prob = model.predict_proba(X_test)\n    else:\n        val_prob = None\n        test_prob = None\n    \n    # Calculate metrics for validation set\n    val_metrics = calculate_metrics(y_val, val_predictions, val_prob)\n    test_metrics = calculate_metrics(y_test, test_predictions, test_prob)\n    \n    # Store results\n    results[model_name] = {\n        'validation_metrics': val_metrics,\n        'test_metrics': test_metrics\n    }\n    \n    # Print metrics\n    print(f\"\\n{model_name} Validation Metrics:\")\n    for metric, value in val_metrics.items():\n        print(f\"{metric}: {value:.4f}\")\n    \n    print(f\"\\n{model_name} Test Metrics:\")\n    for metric, value in test_metrics.items():\n        print(f\"{metric}: {value:.4f}\")\n    \n    # Track the best model by accuracy\n    if val_metrics['accuracy'] > best_accuracy:\n        best_accuracy = val_metrics['accuracy']\n        best_model_name = model_name\n\nprint(f\"\\nBest Model Name: {best_model_name}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:37:19.465779Z","iopub.execute_input":"2024-09-26T17:37:19.466149Z","iopub.status.idle":"2024-09-26T17:39:31.397963Z","shell.execute_reply.started":"2024-09-26T17:37:19.466115Z","shell.execute_reply":"2024-09-26T17:39:31.397097Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 2053, number of negative: 3380\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 326400\n[LightGBM] [Info] Number of data points in the train set: 5433, number of used features: 1280\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.377876 -> initscore=-0.498574\n[LightGBM] [Info] Start training from score -0.498574\n\nLGBMClassifier Validation Metrics:\naccuracy: 0.9647\nf1_score: 0.9508\nmcc: 0.9233\nsensitivity: 0.9552\nspecificity: 0.9699\nfdr: 0.0535\nauroc: 0.9948\nauprc: 0.9898\n\nLGBMClassifier Test Metrics:\naccuracy: 0.9768\nf1_score: 0.9688\nmcc: 0.9503\nsensitivity: 0.9716\nspecificity: 0.9799\nfdr: 0.0341\nauroc: 0.9973\nauprc: 0.9955\n\nXGBClassifier Validation Metrics:\naccuracy: 0.9691\nf1_score: 0.9573\nmcc: 0.9333\nsensitivity: 0.9691\nspecificity: 0.9690\nfdr: 0.0542\nauroc: 0.9942\nauprc: 0.9884\n\nXGBClassifier Test Metrics:\naccuracy: 0.9763\nf1_score: 0.9680\nmcc: 0.9491\nsensitivity: 0.9701\nspecificity: 0.9799\nfdr: 0.0342\nauroc: 0.9970\nauprc: 0.9947\n\nRandomForestClassifier Validation Metrics:\naccuracy: 0.9630\nf1_score: 0.9482\nmcc: 0.9194\nsensitivity: 0.9460\nspecificity: 0.9725\nfdr: 0.0496\nauroc: 0.9945\nauprc: 0.9895\n\nRandomForestClassifier Test Metrics:\naccuracy: 0.9730\nf1_score: 0.9630\nmcc: 0.9419\nsensitivity: 0.9507\nspecificity: 0.9860\nfdr: 0.0245\nauroc: 0.9965\nauprc: 0.9926\n\nAdaBoostClassifier Validation Metrics:\naccuracy: 0.9575\nf1_score: 0.9415\nmcc: 0.9084\nsensitivity: 0.9568\nspecificity: 0.9579\nfdr: 0.0732\nauroc: 0.9895\nauprc: 0.9781\n\nAdaBoostClassifier Test Metrics:\naccuracy: 0.9514\nf1_score: 0.9349\nmcc: 0.8963\nsensitivity: 0.9433\nspecificity: 0.9562\nfdr: 0.0733\nauroc: 0.9905\nauprc: 0.9840\n\nLogisticRegression Validation Metrics:\naccuracy: 0.9625\nf1_score: 0.9486\nmcc: 0.9196\nsensitivity: 0.9691\nspecificity: 0.9587\nfdr: 0.0710\nauroc: 0.9937\nauprc: 0.9796\n\nLogisticRegression Test Metrics:\naccuracy: 0.9735\nf1_score: 0.9644\nmcc: 0.9434\nsensitivity: 0.9716\nspecificity: 0.9746\nfdr: 0.0426\nauroc: 0.9946\nauprc: 0.9908\n\nSVC Validation Metrics:\naccuracy: 0.9431\nf1_score: 0.9208\nmcc: 0.8765\nsensitivity: 0.9244\nspecificity: 0.9536\nfdr: 0.0827\nauroc: 0.9881\nauprc: 0.9747\n\nSVC Test Metrics:\naccuracy: 0.9432\nf1_score: 0.9228\nmcc: 0.8779\nsensitivity: 0.9194\nspecificity: 0.9571\nfdr: 0.0737\nauroc: 0.9869\nauprc: 0.9765\n\nQuadraticDiscriminantAnalysis Validation Metrics:\naccuracy: 0.8669\nf1_score: 0.7737\nmcc: 0.7190\nsensitivity: 0.6358\nspecificity: 0.9957\nfdr: 0.0120\nauroc: 0.8617\nauprc: 0.9060\n\nQuadraticDiscriminantAnalysis Test Metrics:\naccuracy: 0.8720\nf1_score: 0.7910\nmcc: 0.7367\nsensitivity: 0.6552\nspecificity: 0.9991\nfdr: 0.0023\nauroc: 0.8719\nauprc: 0.9184\n\nExtraTreesClassifier Validation Metrics:\naccuracy: 0.9658\nf1_score: 0.9522\nmcc: 0.9255\nsensitivity: 0.9522\nspecificity: 0.9733\nfdr: 0.0478\nauroc: 0.9947\nauprc: 0.9899\n\nExtraTreesClassifier Test Metrics:\naccuracy: 0.9741\nf1_score: 0.9646\nmcc: 0.9442\nsensitivity: 0.9552\nspecificity: 0.9851\nfdr: 0.0259\nauroc: 0.9977\nauprc: 0.9960\n\nBest Model Name: XGBClassifier\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\n# Define base models for stacking\nbase_models = [\n    ('xgb', XGBClassifier(tree_method='gpu_hist', gpu_id=0)),  # XGBoost model with GPU\n    ('svc', SVC(probability=True)),  # Support Vector Classifier with probability enabled\n    ('log_reg', LogisticRegression())  # Logistic Regression\n]\n\n# Create stacking classifier\nstacking_model = StackingClassifier(\n    estimators=base_models,\n    final_estimator=LogisticRegression(),  # Final meta-classifier\n    cv=5  # Use 5-fold cross-validation\n)\n\n# Fit the stacking model\nstacking_model.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:39:31.399144Z","iopub.execute_input":"2024-09-26T17:39:31.399437Z","iopub.status.idle":"2024-09-26T17:41:36.471708Z","shell.execute_reply.started":"2024-09-26T17:39:31.399411Z","shell.execute_reply":"2024-09-26T17:41:36.470778Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"StackingClassifier(cv=5,\n                   estimators=[('xgb',\n                                XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              gpu_id=0, grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=...\n                                              learning_rate=None, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=None, n_jobs=None,\n                                              num_parallel_tree=None, ...)),\n                               ('svc', SVC(probability=True)),\n                               ('log_reg', LogisticRegression())],\n                   final_estimator=LogisticRegression())","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n                   estimators=[(&#x27;xgb&#x27;,\n                                XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              gpu_id=0, grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=...\n                                              learning_rate=None, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=None, n_jobs=None,\n                                              num_parallel_tree=None, ...)),\n                               (&#x27;svc&#x27;, SVC(probability=True)),\n                               (&#x27;log_reg&#x27;, LogisticRegression())],\n                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n                   estimators=[(&#x27;xgb&#x27;,\n                                XGBClassifier(base_score=None, booster=None,\n                                              callbacks=None,\n                                              colsample_bylevel=None,\n                                              colsample_bynode=None,\n                                              colsample_bytree=None,\n                                              device=None,\n                                              early_stopping_rounds=None,\n                                              enable_categorical=False,\n                                              eval_metric=None,\n                                              feature_types=None, gamma=None,\n                                              gpu_id=0, grow_policy=None,\n                                              importance_type=None,\n                                              interaction_constraints=...\n                                              learning_rate=None, max_bin=None,\n                                              max_cat_threshold=None,\n                                              max_cat_to_onehot=None,\n                                              max_delta_step=None,\n                                              max_depth=None, max_leaves=None,\n                                              min_child_weight=None,\n                                              missing=nan,\n                                              monotone_constraints=None,\n                                              multi_strategy=None,\n                                              n_estimators=None, n_jobs=None,\n                                              num_parallel_tree=None, ...)),\n                               (&#x27;svc&#x27;, SVC(probability=True)),\n                               (&#x27;log_reg&#x27;, LogisticRegression())],\n                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=0, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>log_reg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Make predictions on validation and test sets\nval_predictions = stacking_model.predict(X_val)\ntest_predictions = stacking_model.predict(X_test)\n\n# Probability predictions for ROC and AUPRC\nif hasattr(stacking_model, \"predict_proba\"):\n    val_prob = stacking_model.predict_proba(X_val)\n    test_prob = stacking_model.predict_proba(X_test)\nelse:\n    val_prob = None\n    test_prob = None\n\n# Calculate metrics for validation set\nval_metrics = calculate_metrics(y_val, val_predictions, val_prob)\ntest_metrics = calculate_metrics(y_test, test_predictions, test_prob)\n\n# Print stacking model metrics\nprint(\"\\nStacking Model Validation Metrics:\")\nfor metric, value in val_metrics.items():\n    print(f\"{metric}: {value:.4f}\")\n\nprint(\"\\nStacking Model Test Metrics:\")\nfor metric, value in test_metrics.items():\n    print(f\"{metric}: {value:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:41:36.473213Z","iopub.execute_input":"2024-09-26T17:41:36.473778Z","iopub.status.idle":"2024-09-26T17:41:45.247803Z","shell.execute_reply.started":"2024-09-26T17:41:36.473745Z","shell.execute_reply":"2024-09-26T17:41:45.244479Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nStacking Model Validation Metrics:\naccuracy: 0.9691\nf1_score: 0.9573\nmcc: 0.9332\nsensitivity: 0.9676\nspecificity: 0.9699\nfdr: 0.0529\nauroc: 0.9952\nauprc: 0.9909\n\nStacking Model Test Metrics:\naccuracy: 0.9779\nf1_score: 0.9703\nmcc: 0.9527\nsensitivity: 0.9746\nspecificity: 0.9799\nfdr: 0.0340\nauroc: 0.9950\nauprc: 0.9929\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:41:45.249651Z","iopub.execute_input":"2024-09-26T17:41:45.250243Z","iopub.status.idle":"2024-09-26T17:41:45.258166Z","shell.execute_reply.started":"2024-09-26T17:41:45.250200Z","shell.execute_reply":"2024-09-26T17:41:45.256773Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Perform cross-validation for stacking model using the training set\nn_folds = 5  # You can adjust this number\ncv_scores = cross_val_score(stacking_model, X_train, y_train, cv=n_folds, scoring='accuracy')\n\n# Calculate average cross-validation score\naverage_cv_score = cv_scores.mean()\nstd_cv_score = cv_scores.std()\n\n# Print cross-validation results\nprint(\"\\nCross-Validation Scores for Stacking Model:\")\nprint(f\"Scores: {cv_scores}\")\nprint(f\"Average Score: {average_cv_score:.4f} ± {std_cv_score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T17:41:45.262135Z","iopub.execute_input":"2024-09-26T17:41:45.262660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}