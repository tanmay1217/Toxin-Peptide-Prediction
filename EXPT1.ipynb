{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8916680,"sourceType":"datasetVersion","datasetId":5362429},{"sourceId":9088210,"sourceType":"datasetVersion","datasetId":5483863}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T16:18:56.771624Z","iopub.execute_input":"2024-08-05T16:18:56.772846Z","iopub.status.idle":"2024-08-05T16:18:56.792559Z","shell.execute_reply.started":"2024-08-05T16:18:56.772774Z","shell.execute_reply":"2024-08-05T16:18:56.791299Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"/kaggle/input/cobmineddb/combined_protein.csv\n/kaggle/input/cobmineddb/combined_peptides.csv\n/kaggle/input/toxin-database/peptide.csv\n/kaggle/input/toxin-database/protein_test1002.csv\n/kaggle/input/toxin-database/protein_train1002.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n# Load the dataset\nfile_path = '/kaggle/input/cobmineddb/combined_protein.csv'\nprotein_data = pd.read_csv(file_path)\nprotein_data","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:18:56.946205Z","iopub.execute_input":"2024-08-05T16:18:56.947384Z","iopub.status.idle":"2024-08-05T16:18:57.004853Z","shell.execute_reply.started":"2024-08-05T16:18:56.947339Z","shell.execute_reply":"2024-08-05T16:18:57.003711Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"              name                                           sequence  label  \\\n0     >HPCL1_XENTR  MGKQNSKLRPEVLQDLRENTEFTDHELQEWYKGFLKDCPTGHLTVE...      0   \n1      >SIX4_HOTTS  DGYIKGNKGCKVSCVINNVFCNSMCKSSGGSYGYCWSWGLACWCEG...      1   \n2     >TAG2L_AGEOR  MRAIISLLLISAMVFSIIEAVPEEEGLQLSEDERGGCLPHNRFCNA...      1   \n3     >P2011_DANRE  MKTKFTKKTVLKFFGILFAILLLSVLILFSVVIGRTFTFKVNRELG...      0   \n4      >O165_CONTE  MKLTCMVIVAVLFLTAWTFVTAITSNGLENLFPNAHHEMKNPEASK...      1   \n...            ...                                                ...    ...   \n9051  >EMC2B_XENLA  MSKVSDLYDVTWEDMRDKMKTWREDNYRNSEQIVDVGEELINEHAS...      0   \n9052   >COLI_LITCT  MLQPVWHACILAILGVFIFHVGEVRSQCWESNKCTDLSSEDGILEC...      0   \n9053  >MED30_DANRE  MTTPPLAQFSGQQQQQTQAARDVNTASLCRIGQETVQDIVLRTMEI...      0   \n9054  >RB87F_DROME  MAEQNDSNGNYDDGEEITEPEQLRKLFIGGLDYRTTDDGLKAHFEK...      0   \n9055   >RS17_SPOFR  MGRVRTKTVKKAAKIIIEKYYTRLTLDFDTNKRICEEIAIIPTKPL...      0   \n\n      sequence_length  \n0                 193  \n1                  62  \n2                  70  \n3                 515  \n4                  76  \n...               ...  \n9051              297  \n9052              263  \n9053              174  \n9054              385  \n9055              133  \n\n[9056 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>sequence</th>\n      <th>label</th>\n      <th>sequence_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&gt;HPCL1_XENTR</td>\n      <td>MGKQNSKLRPEVLQDLRENTEFTDHELQEWYKGFLKDCPTGHLTVE...</td>\n      <td>0</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&gt;SIX4_HOTTS</td>\n      <td>DGYIKGNKGCKVSCVINNVFCNSMCKSSGGSYGYCWSWGLACWCEG...</td>\n      <td>1</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&gt;TAG2L_AGEOR</td>\n      <td>MRAIISLLLISAMVFSIIEAVPEEEGLQLSEDERGGCLPHNRFCNA...</td>\n      <td>1</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&gt;P2011_DANRE</td>\n      <td>MKTKFTKKTVLKFFGILFAILLLSVLILFSVVIGRTFTFKVNRELG...</td>\n      <td>0</td>\n      <td>515</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&gt;O165_CONTE</td>\n      <td>MKLTCMVIVAVLFLTAWTFVTAITSNGLENLFPNAHHEMKNPEASK...</td>\n      <td>1</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9051</th>\n      <td>&gt;EMC2B_XENLA</td>\n      <td>MSKVSDLYDVTWEDMRDKMKTWREDNYRNSEQIVDVGEELINEHAS...</td>\n      <td>0</td>\n      <td>297</td>\n    </tr>\n    <tr>\n      <th>9052</th>\n      <td>&gt;COLI_LITCT</td>\n      <td>MLQPVWHACILAILGVFIFHVGEVRSQCWESNKCTDLSSEDGILEC...</td>\n      <td>0</td>\n      <td>263</td>\n    </tr>\n    <tr>\n      <th>9053</th>\n      <td>&gt;MED30_DANRE</td>\n      <td>MTTPPLAQFSGQQQQQTQAARDVNTASLCRIGQETVQDIVLRTMEI...</td>\n      <td>0</td>\n      <td>174</td>\n    </tr>\n    <tr>\n      <th>9054</th>\n      <td>&gt;RB87F_DROME</td>\n      <td>MAEQNDSNGNYDDGEEITEPEQLRKLFIGGLDYRTTDDGLKAHFEK...</td>\n      <td>0</td>\n      <td>385</td>\n    </tr>\n    <tr>\n      <th>9055</th>\n      <td>&gt;RS17_SPOFR</td>\n      <td>MGRVRTKTVKKAAKIIIEKYYTRLTLDFDTNKRICEEIAIIPTKPL...</td>\n      <td>0</td>\n      <td>133</td>\n    </tr>\n  </tbody>\n</table>\n<p>9056 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the dataset\nfile_path = '/kaggle/input/cobmineddb/combined_peptides.csv'\npeptide_data = pd.read_csv(file_path)\npeptide_data","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:18:57.081275Z","iopub.execute_input":"2024-08-05T16:18:57.081721Z","iopub.status.idle":"2024-08-05T16:18:57.105006Z","shell.execute_reply.started":"2024-08-05T16:18:57.081688Z","shell.execute_reply":"2024-08-05T16:18:57.103886Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"              name                                         sequence  label  \\\n0     >COC2C_CONCL    DVCDSLVGGRCIHNGCYCERDAPNGNCCNTDGCTARWWCPGTKWD      1   \n1      >NA15_ANTXA  GVSCLCDSDGPSVSGNTLSGIIWLAGCPSGWHNCKAHGPNIGWCCKK      1   \n2      >PPK6_SHELA                                   SESEVPGMWFGPRL      0   \n3       >SK1_BLAGE                                      EQFDDYGHMRF      0   \n4      >COMB_CONMA          AATCTHWALIYFKTVQLFGWHFNYQVDATYCPQFQPCMP      1   \n...            ...                                              ...    ...   \n5616           NaN                         EDDHHHHHHHHHGVGGGGGGGGGG      0   \n5617           NaN        MTTNTQYIYPIFTVRWLAVHALAVPTVFFLGSISAMQFIQR      0   \n5618           NaN                              GILDVAKTLVGKLRNVLGI      0   \n5619           NaN   MKVLSSLASAKTRYPDCQVVRRRGRVYVICKSNPRFKAVQGRKKRR      0   \n5620           NaN  MKSIDLTILSLKRKGIRTEKVLKNQNPDRLSHMTDKNAQPKSKEKEE      0   \n\n      sequence_length  \n0                  45  \n1                  47  \n2                  14  \n3                  11  \n4                  39  \n...               ...  \n5616               24  \n5617               41  \n5618               19  \n5619               46  \n5620               47  \n\n[5621 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>sequence</th>\n      <th>label</th>\n      <th>sequence_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&gt;COC2C_CONCL</td>\n      <td>DVCDSLVGGRCIHNGCYCERDAPNGNCCNTDGCTARWWCPGTKWD</td>\n      <td>1</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&gt;NA15_ANTXA</td>\n      <td>GVSCLCDSDGPSVSGNTLSGIIWLAGCPSGWHNCKAHGPNIGWCCKK</td>\n      <td>1</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&gt;PPK6_SHELA</td>\n      <td>SESEVPGMWFGPRL</td>\n      <td>0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&gt;SK1_BLAGE</td>\n      <td>EQFDDYGHMRF</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&gt;COMB_CONMA</td>\n      <td>AATCTHWALIYFKTVQLFGWHFNYQVDATYCPQFQPCMP</td>\n      <td>1</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5616</th>\n      <td>NaN</td>\n      <td>EDDHHHHHHHHHGVGGGGGGGGGG</td>\n      <td>0</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>5617</th>\n      <td>NaN</td>\n      <td>MTTNTQYIYPIFTVRWLAVHALAVPTVFFLGSISAMQFIQR</td>\n      <td>0</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>5618</th>\n      <td>NaN</td>\n      <td>GILDVAKTLVGKLRNVLGI</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>5619</th>\n      <td>NaN</td>\n      <td>MKVLSSLASAKTRYPDCQVVRRRGRVYVICKSNPRFKAVQGRKKRR</td>\n      <td>0</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>5620</th>\n      <td>NaN</td>\n      <td>MKSIDLTILSLKRKGIRTEKVLKNQNPDRLSHMTDKNAQPKSKEKEE</td>\n      <td>0</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n<p>5621 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install lazypredict\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter  # Import Counter\nimport itertools\nfrom lazypredict.Supervised import LazyClassifier\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:18:57.383769Z","iopub.execute_input":"2024-08-05T16:18:57.384290Z","iopub.status.idle":"2024-08-05T16:19:12.484933Z","shell.execute_reply.started":"2024-08-05T16:18:57.384255Z","shell.execute_reply":"2024-08-05T16:19:12.483178Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Protein Prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport itertools\nfrom collections import Counter\nfrom lazypredict.Supervised import LazyClassifier\n\n# Load the dataset\ndata = protein_data\n\n# Define the feature extraction functions\ndef calculate_aac(sequence):\n    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n    sequence_length = len(sequence)\n    aa_count = Counter(sequence)\n    aac = [aa_count[aa] / sequence_length for aa in amino_acids]\n    return aac\n\ndef calculate_dpc(sequence):\n    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n    dipeptides = [''.join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n    dipeptide_count = Counter([sequence[i:i+2] for i in range(len(sequence)-1)])\n    sequence_length = len(sequence) - 1\n    dpc = [dipeptide_count[dp] / sequence_length for dp in dipeptides]\n    return dpc\n\n# Extract features for a given dataset with renamed columns to avoid overlap\ndef extract_features(data):\n    aac_features = data['sequence'].apply(calculate_aac)\n    dpc_features = data['sequence'].apply(calculate_dpc) \n\n    aac_df = pd.DataFrame(aac_features.tolist(), columns=[f'aac_{i}' for i in range(20)])\n    dpc_df = pd.DataFrame(dpc_features.tolist(), columns=[f'dpc_{i}' for i in range(400)])\n  \n    features = aac_df.join(dpc_df)\n    \n    return features\n\n# Extract features and save them to CSV\nfeatures = extract_features(data)\nfeatures['label'] = data['label']\nfeatures.to_csv('/kaggle/working/protein_features.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:19:12.488171Z","iopub.execute_input":"2024-08-05T16:19:12.488714Z","iopub.status.idle":"2024-08-05T16:19:22.604688Z","shell.execute_reply.started":"2024-08-05T16:19:12.488664Z","shell.execute_reply":"2024-08-05T16:19:22.603384Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Load the features from the saved CSV\nloaded_data = pd.read_csv('/kaggle/working/protein_features.csv')\n\n# Split the data into training (60%), validation (20%), and testing (20%) sets\ntrain_data, temp_data = train_test_split(loaded_data, test_size=0.4, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\n# Separate features and labels\nX_train = train_data.drop(columns=['label'])\ny_train = train_data['label']\nX_val = val_data.drop(columns=['label'])\ny_val = val_data['label']\nX_test = test_data.drop(columns=['label'])\ny_test = test_data['label']\n\n# Evaluate models using LazyPredict\nclf = LazyClassifier()\nmodels, predictions = clf.fit(X_train, X_val, y_train, y_val)\n\n# Display model performance\nprint(models)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:19:22.606141Z","iopub.execute_input":"2024-08-05T16:19:22.606499Z","iopub.status.idle":"2024-08-05T16:21:11.740020Z","shell.execute_reply.started":"2024-08-05T16:19:22.606469Z","shell.execute_reply":"2024-08-05T16:21:11.738872Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [01:39<00:03,  3.11s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 2053, number of negative: 3380\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 105697\n[LightGBM] [Info] Number of data points in the train set: 5433, number of used features: 420\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.377876 -> initscore=-0.498574\n[LightGBM] [Info] Start training from score -0.498574\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [01:48<00:00,  3.74s/it]","output_type":"stream"},{"name":"stdout","text":"                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nLGBMClassifier                     0.95               0.95     0.95      0.95   \nXGBClassifier                      0.95               0.95     0.95      0.95   \nSVC                                0.95               0.95     0.95      0.95   \nExtraTreesClassifier               0.95               0.94     0.94      0.95   \nRandomForestClassifier             0.94               0.94     0.94      0.94   \nBaggingClassifier                  0.93               0.92     0.92      0.93   \nLinearDiscriminantAnalysis         0.93               0.92     0.92      0.93   \nRidgeClassifierCV                  0.93               0.91     0.91      0.93   \nRidgeClassifier                    0.93               0.91     0.91      0.93   \nLogisticRegression                 0.92               0.91     0.91      0.92   \nQuadraticDiscriminantAnalysis      0.90               0.91     0.91      0.90   \nAdaBoostClassifier                 0.91               0.91     0.91      0.91   \nLinearSVC                          0.92               0.90     0.90      0.92   \nCalibratedClassifierCV             0.91               0.90     0.90      0.91   \nPassiveAggressiveClassifier        0.91               0.90     0.90      0.91   \nDecisionTreeClassifier             0.90               0.89     0.89      0.90   \nSGDClassifier                      0.90               0.89     0.89      0.90   \nPerceptron                         0.89               0.88     0.88      0.89   \nNearestCentroid                    0.89               0.87     0.87      0.89   \nNuSVC                              0.87               0.87     0.87      0.87   \nGaussianNB                         0.84               0.83     0.83      0.84   \nExtraTreeClassifier                0.84               0.83     0.83      0.84   \nBernoulliNB                        0.83               0.82     0.82      0.83   \nKNeighborsClassifier               0.87               0.82     0.82      0.86   \nLabelSpreading                     0.71               0.59     0.59      0.63   \nLabelPropagation                   0.71               0.59     0.59      0.63   \nDummyClassifier                    0.64               0.50     0.50      0.50   \n\n                               Time Taken  \nModel                                      \nLGBMClassifier                       8.65  \nXGBClassifier                        7.14  \nSVC                                  5.08  \nExtraTreesClassifier                 2.06  \nRandomForestClassifier               6.91  \nBaggingClassifier                   19.52  \nLinearDiscriminantAnalysis           1.07  \nRidgeClassifierCV                    1.14  \nRidgeClassifier                      0.44  \nLogisticRegression                   0.92  \nQuadraticDiscriminantAnalysis        1.30  \nAdaBoostClassifier                   6.85  \nLinearSVC                            6.11  \nCalibratedClassifierCV              20.73  \nPassiveAggressiveClassifier          0.31  \nDecisionTreeClassifier               3.52  \nSGDClassifier                        0.83  \nPerceptron                           0.26  \nNearestCentroid                      0.25  \nNuSVC                                8.53  \nGaussianNB                           0.16  \nExtraTreeClassifier                  0.14  \nBernoulliNB                          0.33  \nKNeighborsClassifier                 0.66  \nLabelSpreading                       2.80  \nLabelPropagation                     2.26  \nDummyClassifier                      0.11  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"y_val","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:22:00.806128Z","iopub.execute_input":"2024-08-05T16:22:00.806499Z","iopub.status.idle":"2024-08-05T16:22:00.830335Z","shell.execute_reply.started":"2024-08-05T16:22:00.806470Z","shell.execute_reply":"2024-08-05T16:22:00.829068Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"1720    0\n856     1\n1617    1\n2127    1\n2133    1\n       ..\n205     1\n3825    0\n1175    1\n3153    1\n1345    0\nName: label, Length: 1124, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:11.753552Z","iopub.execute_input":"2024-08-05T16:21:11.753918Z","iopub.status.idle":"2024-08-05T16:21:11.775901Z","shell.execute_reply.started":"2024-08-05T16:21:11.753889Z","shell.execute_reply":"2024-08-05T16:21:11.774652Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"4844    0\n4970    1\n748     0\n3105    0\n7425    0\n       ..\n7457    1\n1586    1\n1242    0\n8840    0\n8254    0\nName: label, Length: 1812, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"best_model = models.index[0]\nbest_model","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:11.777427Z","iopub.execute_input":"2024-08-05T16:21:11.777780Z","iopub.status.idle":"2024-08-05T16:21:11.792481Z","shell.execute_reply.started":"2024-08-05T16:21:11.777751Z","shell.execute_reply":"2024-08-05T16:21:11.791501Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'LGBMClassifier'"},"metadata":{}}]},{"cell_type":"code","source":"# Import necessary libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\n# Define the top models with their names as keys\nmodel_dict = {\n    'LGBMClassifier': LGBMClassifier(),\n    'XGBClassifier': XGBClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n}\n\n# Retrieve the name of the best model (e.g., 'LGBMClassifier')\nbest_model_name = models.index[0]\n\n# Initialize the best model from the model_dict using the best_model_name\nbest_model = model_dict[best_model_name]\n\n# Fit the best model on the training data\nbest_model.fit(X_train, y_train)\n\n# Predict on the validation data\nval_predictions = best_model.predict(X_val)\nval_accuracy = (val_predictions == y_val).mean()\n\n# Predict on the test data\ntest_predictions = best_model.predict(X_test)\ntest_accuracy = (test_predictions == y_test).mean()\n\n# Print the accuracy results\nprint(f\"Best Model: {best_model_name}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:11.793769Z","iopub.execute_input":"2024-08-05T16:21:11.794172Z","iopub.status.idle":"2024-08-05T16:21:18.012561Z","shell.execute_reply.started":"2024-08-05T16:21:11.794142Z","shell.execute_reply":"2024-08-05T16:21:18.011497Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 2053, number of negative: 3380\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039291 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 105521\n[LightGBM] [Info] Number of data points in the train set: 5433, number of used features: 420\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.377876 -> initscore=-0.498574\n[LightGBM] [Info] Start training from score -0.498574\nBest Model: LGBMClassifier\nValidation Accuracy: 0.9531\nTest Accuracy: 0.9570\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Peptide prediction","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport itertools\nfrom collections import Counter\nfrom lazypredict.Supervised import LazyClassifier\n\n# Load the dataset\ndata = peptide_data\n\n# Define the feature extraction functions\ndef calculate_aac(sequence):\n    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n    sequence_length = len(sequence)\n    aa_count = Counter(sequence)\n    aac = [aa_count[aa] / sequence_length for aa in amino_acids]\n    return aac\n\ndef calculate_dpc(sequence):\n    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n    dipeptides = [''.join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n    dipeptide_count = Counter([sequence[i:i+2] for i in range(len(sequence)-1)])\n    sequence_length = len(sequence) - 1\n    dpc = [dipeptide_count[dp] / sequence_length for dp in dipeptides]\n    return dpc\n\n# Extract features for a given dataset with renamed columns to avoid overlap\ndef extract_features(data):\n    aac_features = data['sequence'].apply(calculate_aac)\n    dpc_features = data['sequence'].apply(calculate_dpc)\n\n    aac_df = pd.DataFrame(aac_features.tolist(), columns=[f'aac_{i}' for i in range(20)])\n    dpc_df = pd.DataFrame(dpc_features.tolist(), columns=[f'dpc_{i}' for i in range(400)])\n\n    features = aac_df.join(dpc_df)\n    \n    return features\n\n# Extract features and save them to CSV\nfeatures = extract_features(data)\nfeatures['label'] = data['label']\nfeatures.to_csv('/kaggle/working/peptide_features.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:18.013792Z","iopub.execute_input":"2024-08-05T16:21:18.014157Z","iopub.status.idle":"2024-08-05T16:21:22.795781Z","shell.execute_reply.started":"2024-08-05T16:21:18.014129Z","shell.execute_reply":"2024-08-05T16:21:22.794374Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Load the features from the saved CSV\nloaded_data = pd.read_csv('/kaggle/working/peptide_features.csv')\n\n# Split the data into training (60%), validation (20%), and testing (20%) sets\ntrain_data, temp_data = train_test_split(loaded_data, test_size=0.4, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\n# Separate features and labels\nX_train = train_data.drop(columns=['label'])\ny_train = train_data['label']\nX_val = val_data.drop(columns=['label'])\ny_val = val_data['label']\nX_test = test_data.drop(columns=['label'])\ny_test = test_data['label']\n\n# Evaluate models using LazyPredict\nclf = LazyClassifier()\nmodels, predictions = clf.fit(X_train, X_val, y_train, y_val)\n\n# Display model performance\nprint(models)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:22.797566Z","iopub.execute_input":"2024-08-05T16:21:22.797922Z","iopub.status.idle":"2024-08-05T16:21:58.674794Z","shell.execute_reply.started":"2024-08-05T16:21:22.797894Z","shell.execute_reply":"2024-08-05T16:21:58.673418Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":" 97%|█████████▋| 28/29 [00:34<00:01,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1812, number of negative: 1560\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013425 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 15926\n[LightGBM] [Info] Number of data points in the train set: 3372, number of used features: 419\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.537367 -> initscore=0.149745\n[LightGBM] [Info] Start training from score 0.149745\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29/29 [00:35<00:00,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nXGBClassifier                      0.94               0.94     0.94      0.94   \nLGBMClassifier                     0.93               0.93     0.93      0.93   \nExtraTreesClassifier               0.93               0.93     0.93      0.93   \nRandomForestClassifier             0.93               0.93     0.93      0.93   \nSVC                                0.92               0.92     0.92      0.92   \nBaggingClassifier                  0.92               0.92     0.92      0.92   \nQuadraticDiscriminantAnalysis      0.91               0.91     0.91      0.91   \nDecisionTreeClassifier             0.89               0.89     0.89      0.89   \nNuSVC                              0.88               0.88     0.88      0.88   \nLogisticRegression                 0.88               0.88     0.88      0.88   \nLinearDiscriminantAnalysis         0.88               0.88     0.88      0.88   \nRidgeClassifier                    0.88               0.88     0.88      0.88   \nRidgeClassifierCV                  0.88               0.88     0.88      0.88   \nCalibratedClassifierCV             0.88               0.88     0.88      0.88   \nLinearSVC                          0.87               0.87     0.87      0.87   \nAdaBoostClassifier                 0.87               0.87     0.87      0.87   \nExtraTreeClassifier                0.87               0.86     0.86      0.87   \nSGDClassifier                      0.86               0.86     0.86      0.86   \nPerceptron                         0.86               0.86     0.86      0.86   \nPassiveAggressiveClassifier        0.86               0.86     0.86      0.86   \nKNeighborsClassifier               0.85               0.85     0.85      0.85   \nNearestCentroid                    0.84               0.85     0.85      0.84   \nGaussianNB                         0.84               0.84     0.84      0.84   \nBernoulliNB                        0.83               0.84     0.84      0.83   \nLabelSpreading                     0.64               0.66     0.66      0.60   \nLabelPropagation                   0.64               0.66     0.66      0.60   \nDummyClassifier                    0.54               0.50     0.50      0.38   \n\n                               Time Taken  \nModel                                      \nXGBClassifier                        1.74  \nLGBMClassifier                       1.18  \nExtraTreesClassifier                 1.35  \nRandomForestClassifier               1.77  \nSVC                                  2.40  \nBaggingClassifier                    2.55  \nQuadraticDiscriminantAnalysis        0.95  \nDecisionTreeClassifier               0.46  \nNuSVC                                2.84  \nLogisticRegression                   0.69  \nLinearDiscriminantAnalysis           0.79  \nRidgeClassifier                      0.35  \nRidgeClassifierCV                    0.86  \nCalibratedClassifierCV               8.90  \nLinearSVC                            2.74  \nAdaBoostClassifier                   1.31  \nExtraTreeClassifier                  0.10  \nSGDClassifier                        0.41  \nPerceptron                           0.25  \nPassiveAggressiveClassifier          0.26  \nKNeighborsClassifier                 0.28  \nNearestCentroid                      0.20  \nGaussianNB                           0.11  \nBernoulliNB                          0.23  \nLabelSpreading                       1.34  \nLabelPropagation                     1.11  \nDummyClassifier                      0.08  \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = models.index[0]\nbest_model","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:58.679226Z","iopub.execute_input":"2024-08-05T16:21:58.679740Z","iopub.status.idle":"2024-08-05T16:21:58.692582Z","shell.execute_reply.started":"2024-08-05T16:21:58.679694Z","shell.execute_reply":"2024-08-05T16:21:58.691164Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'XGBClassifier'"},"metadata":{}}]},{"cell_type":"code","source":"# Import necessary libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\n# Define the top models with their names as keys\nmodel_dict = {\n    'LGBMClassifier': LGBMClassifier(),\n    'XGBClassifier': XGBClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n}\n\n# Retrieve the name of the best model (e.g., 'LGBMClassifier')\nbest_model_name = models.index[0]\n\n# Initialize the best model from the model_dict using the best_model_name\nbest_model = model_dict[best_model_name]\n\n# Fit the best model on the training data\nbest_model.fit(X_train, y_train)\n\n# Predict on the validation data\nval_predictions = best_model.predict(X_val)\nval_accuracy = (val_predictions == y_val).mean()\n\n# Predict on the test data\ntest_predictions = best_model.predict(X_test)\ntest_accuracy = (test_predictions == y_test).mean()\n\n# Print the accuracy results\nprint(f\"Best Model: {best_model_name}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:21:58.694412Z","iopub.execute_input":"2024-08-05T16:21:58.694923Z","iopub.status.idle":"2024-08-05T16:22:00.796195Z","shell.execute_reply.started":"2024-08-05T16:21:58.694876Z","shell.execute_reply":"2024-08-05T16:22:00.794646Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Best Model: XGBClassifier\nValidation Accuracy: 0.9359\nTest Accuracy: 0.9298\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}